{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import scipy.signal as sps\n",
    "from scipy.stats import zscore\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def data_plotter(variable_to_plot):\n",
    "    # This function will take any slice of your dataframes (e.g. signals_train.Amb_WindSpeed_Avg['T01'])\n",
    "    # and plot its value against time.\n",
    "    # This requires you to have the timestamp as an index.\n",
    "    # Also allows to plot the first n points of the series (e.g. data_plotter(signals_train.Amb_WindSpeed_Avg['T01'][0:1000]) )\n",
    "    \n",
    "    plt.rc('font', size=10) \n",
    "    fig1,axs1 = plt.subplots(1,1,figsize = (6,6))\n",
    "    axs1.plot(variable_to_plot.index,variable_to_plot.values)\n",
    "    plt.tight_layout()             \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def power_cepstrum(signal,cepstrum_length,fs,cutoff):\n",
    "    _, Pyy = sps.welch(signal,fs,nperseg=cepstrum_length,nfft=2**10,return_onesided=True)\n",
    "#    _, Pyy = sps.welch(signal,fs,nfft=2**12,return_onesided=True)\n",
    "\n",
    "    powerceps = np.abs(np.fft.irfft(np.log(Pyy,out=np.zeros_like(Pyy), where=(Pyy!=0)))) \n",
    "    return powerceps[:cutoff]\n",
    "\n",
    "def rolling_window(a, window, step_size):\n",
    "    shape = (np.int((a.shape[-1]-window)/step_size),window)\n",
    "    rolled = np.empty(shape)\n",
    "    \n",
    "    for i in np.arange(shape[0]):\n",
    "        rolled[i,:] = a[i*step_size: i*step_size + window]\n",
    "    \n",
    "    return rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "failures_train = pd.read_csv('wind-farm-1-failures-training.csv',sep=';')\n",
    "logs_train = pd.read_csv('wind-farm-1-logs-training.csv',sep=';')\n",
    "metmast_train = pd.read_csv('wind-farm-1-metmast-training.csv',sep=';')\n",
    "signals_train = pd.read_csv('wind-farm-1-signals-training.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add turbines and timestamps as indices. \n",
    "# Translate time stamps to datetime objects\n",
    "\n",
    "failures_train.Timestamp = pd.to_datetime(failures_train.Timestamp)\n",
    "failures_train.Timestamp = failures_train.Timestamp.apply(lambda d: d.replace(tzinfo=None))\n",
    "failures_train.set_index(['Turbine_ID','Timestamp'],inplace = True) # this line adds them as index and removes them as regular column\n",
    "#failures_train.set_index(['Turbine_ID','Timestamp']) # this line adds them as index and keeps the regular columns\n",
    "\n",
    "logs_train.TimeDetected = pd.to_datetime(logs_train.TimeDetected)\n",
    "logs_train.TimeDetected = logs_train.TimeDetected.apply(lambda d: d.replace(tzinfo=None))\n",
    "logs_train = logs_train.rename(columns = {'UnitTitle':'Turbine_ID'})  #Here, we rename some columns for consistency.\n",
    "logs_train.set_index(['Turbine_ID','TimeDetected'],inplace = True)\n",
    "\n",
    "metmast_train.Timestamp = pd.to_datetime(metmast_train.Timestamp)\n",
    "metmast_train.Timestamp = metmast_train.Timestamp.apply(lambda d: d.replace(tzinfo=None))\n",
    "metmast_train.set_index(['Timestamp'],inplace = True)\n",
    "\n",
    "signals_train.Timestamp = pd.to_datetime(signals_train.Timestamp)\n",
    "signals_train.Timestamp = signals_train.Timestamp.apply(lambda d: d.replace(tzinfo=None))\n",
    "signals_train.set_index(['Turbine_ID','Timestamp'],inplace = True)\n",
    "#signals_train.set_index(['Turbine_ID','Timestamp'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scada measures the temperature of each phase of the generator\n",
    "# Here we create one combined temperature metric: T_tot = sqrt(Ta^2 + Tb^2 + Tc^2)\n",
    "\n",
    "signals_train['Gen_tot_temp'] = np.sqrt((signals_train['Gen_Phase1_Temp_Avg']**2 + signals_train['Gen_Phase2_Temp_Avg']**2 + signals_train['Gen_Phase3_Temp_Avg']**2)/3)\n",
    "#signals_train['Gen_tot_temp'] = (signals_train['Gen_Phase1_Temp_Avg'] + signals_train['Gen_Phase2_Temp_Avg'] + signals_train['Gen_Phase3_Temp_Avg'])/3\n",
    "\n",
    "\n",
    "# Sort Data\n",
    "signals_train.sort_index(inplace = True)\n",
    "metmast_train.sort_index(inplace = True)\n",
    "\n",
    "failures_train.sort_index(level=0, ascending=True, inplace=True) # sort based on turbine\n",
    "failures_train['Error'] = 1    # Add a column with a numeric value for an error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 1/(10*60)\n",
    "cepstrum_length = 2**7\n",
    "cutoff = 2**6\n",
    "window_length = 24*6*5\n",
    "step_size = 1\n",
    "clustered_turb = 'T06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_windows = rolling_window(signals_train.loc[clustered_turb].Gen_tot_temp,window_length,step_size)\n",
    "input_windows = rolling_window(signals_train.loc[clustered_turb].Amb_WindSpeed_Avg,window_length,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cepstra_windows = np.asarray([power_cepstrum(output_windows[i],cepstrum_length,fs,cutoff) - power_cepstrum(input_windows[i],cepstrum_length,fs,cutoff) for i in np.arange(output_windows.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.sqrt(np.arange(cutoff))\n",
    "windowed_weighted_cepstra = np.nan_to_num(np.asarray([weights * cepstra_windows[i] for i in np.arange(cepstra_windows.shape[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_clusters = 2\n",
    "kmeans = KMeans(n_clusters = amount_of_clusters,n_init=100).fit(windowed_weighted_cepstra)\n",
    "kmeans_euclid = KMeans(n_clusters = amount_of_clusters,n_init=100).fit(output_windows)\n",
    "\n",
    "\n",
    "data_plotter(signals_train.loc[clustered_turb].Gen_tot_temp)\n",
    "data_plotter(signals_train.loc[clustered_turb].Amb_WindSpeed_Avg)\n",
    "plt.plot(failures_train.loc[clustered_turb].index, failures_train.Error[clustered_turb],'.',markersize = 10, color = 'C3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(failures_train[['Remarks','Component']])\n",
    "\n",
    "fault_indices = np.asarray([int((failures_train.loc[clustered_turb].index.to_period('D')[i] - signals_train.loc[clustered_turb].index.to_period(\"D\").unique()[0]).freqstr[:-1]) for i in range(failures_train.loc[clustered_turb].index.to_period('D').size)])\n",
    "fault_indices = 24*6*fault_indices\n",
    "\n",
    "colors = cm.get_cmap('jet',amount_of_clusters)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Cluster labels throughout time of turbine ' + clustered_turb)\n",
    "plt.xlabel('Starting day of window')\n",
    "plt.ylabel('Cluster number')\n",
    "for i in np.arange(amount_of_clusters):  # Note that we only plot the middel five errors here, as for turbine T06, these are the faults related to the generator.\n",
    "    plt.plot(fault_indices[1:-1], failures_train.Error[clustered_turb][1:-1]-1+i,'*',markersize = 10, color = 'black',alpha=0.5)\n",
    "plt.scatter(np.arange(kmeans.labels_.size),kmeans.labels_,color=colors(kmeans.labels_))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Cluster labels throughout time of turbine ' + clustered_turb + ' for Euclidean distance')\n",
    "plt.xlabel('Starting day of window')\n",
    "plt.ylabel('Cluster number')\n",
    "for i in np.arange(amount_of_clusters):\n",
    "    plt.plot(fault_indices[1:-1], failures_train.Error[clustered_turb][1:-1]-1+i,'*',markersize = 10, color = 'black',alpha=0.5)\n",
    "plt.scatter(np.arange(kmeans_euclid.labels_.size),kmeans_euclid.labels_,color=colors(kmeans_euclid.labels_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "\n",
    "#pickle.dump(kmeans_stochastic, open(\"kmeansstochastic.pkl\", \"wb\"))\n",
    "#kmeans = pickle.load(open(\"kmeanscepstral.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('faultdays.csv',fault_indices,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_indices = np.asarray([int((failures_train.loc[clustered_turb].index.to_period('T')[i] - signals_train.loc[clustered_turb].index.to_period(\"T\").unique()[0]).freqstr[:-1]) for i in range(failures_train.loc[clustered_turb].index.to_period('T').size)])\n",
    "fault_indices//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('faulttenminutes.csv',fault_indices//10,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.vstack((np.arange(kmeans.cluster_centers_[0].shape[0]),kmeans.cluster_centers_[0])).shape\n",
    "#np.savetxt('clustercenterscepstral1.csv',np.vstack((np.arange(kmeans.cluster_centers_[0].shape[0]),kmeans.cluster_centers_[1])).T, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
